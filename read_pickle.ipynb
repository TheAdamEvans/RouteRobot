{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = './utah_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grab_children(dest, collect):\n",
    "    if hasattr(dest, 'children'):\n",
    "        for child in dest.children:\n",
    "            collect.append(child.__dict__)\n",
    "            grab_children(child, collect)\n",
    "    return collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def climb_from_dest(dest):\n",
    "    kidnapped = grab_children(dest, collect = []) # kidnapping jokes are not okay\n",
    "    climb = pd.DataFrame.from_dict(kidnapped) # neither are dict jokes\n",
    "    if max(climb.shape) > 0:\n",
    "        climb.set_index(climb.href.values, inplace = True, verify_integrity = False)\n",
    "        return climb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combine_pickle(data_dir):\n",
    "    import os\n",
    "    \n",
    "    collect_climb = []\n",
    "    for area in os.listdir(data_dir):\n",
    "        pkl = '.pickle'\n",
    "        if area[-len(pkl):] != pkl:\n",
    "            pass\n",
    "        else:\n",
    "            dest = pickle.load(open(data_dir + area, 'rb'))        \n",
    "            partial = climb_from_dest(dest)\n",
    "            collect_climb.append(partial)\n",
    "            print len(collect_climb), area[:-len(pkl)]\n",
    "    \n",
    "    climb = pd.concat(collect_climb)\n",
    "    return climb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 beaverboulder\n",
      "2 boxcarwoodyboulders\n",
      "3 burrtraillongcanyon\n",
      "4 capitolreefnationalpark\n",
      "5 cedarcity\n",
      "6 copperridge\n",
      "7 desolationcanyon\n",
      "8 duchesne\n",
      "9 echocanyon\n",
      "10 fishlakenationalforest\n",
      "11 flaminggorge\n",
      "12 gilestownsiteboulders\n",
      "13 glencanyon\n",
      "14 grandstaircase\n",
      "15 greenriver\n",
      "16 hiddenflowkanab\n",
      "17 hillcrestboulders\n",
      "18 houserange\n",
      "19 huntingtoncanyon\n",
      "20 ibex\n",
      "21 joesvalley\n",
      "22 jungleontheaquariusplateau\n",
      "23 kanabcreekcrag\n",
      "24 kolobterracerd\n",
      "25 lakepowell\n",
      "26 logcanyon\n",
      "27 maplecanyon\n",
      "28 maplegrove\n",
      "29 moabarea\n",
      "30 ninemilecanyon\n",
      "31 oquirrhmountains\n",
      "32 parowan\n",
      "33 pricecanyon\n",
      "34 saintgeorge\n",
      "35 saltcreekcanyon\n",
      "36 sanrafaelswell\n",
      "37 springcanyon\n",
      "38 stansburymountains\n",
      "39 thehenrymountains\n",
      "40 triassic\n",
      "41 uintamountains\n",
      "42 vernalarea\n",
      "43 wasatchrange\n",
      "44 westwaterarea\n",
      "45 whiterocks\n",
      "46 zionnationalpark\n"
     ]
    }
   ],
   "source": [
    "climb = combine_pickle(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'area_hierarchy', u'boulder', u'children', u'children_href',\n",
       "       u'commitment', u'description', u'elevation', u'fa', u'feet',\n",
       "       u'getting_there', u'grade', u'href', u'is_area', u'is_route',\n",
       "       u'location', u'name', u'nickname', u'page_views', u'pitches',\n",
       "       u'protect_rate', u'protection', u'season', u'star_rating',\n",
       "       u'submitted_by', u'type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(climb['href'].unique()) / float(len(climb['href']))\n",
    "# YAY the hrefs are unique!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combine_text(jess):\n",
    "    \n",
    "    # ordered by what makes sense\n",
    "    text_field = ['getting_there', 'description', 'protection']\n",
    "    \n",
    "    # loop through text fields appending to a list\n",
    "    # TODO do this with a map\n",
    "    txt_collect = []\n",
    "    for txt in text_field:\n",
    "        if not pd.isnull(jess[txt]):\n",
    "            txt_collect.append(jess[txt])\n",
    "    \n",
    "    return \"\\n\".join(txt_collect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_total_climb_description(climb):\n",
    "    collect = []\n",
    "    for href, cmb in climb.iterrows():\n",
    "        cmbtxt = combine_text(cmb)\n",
    "        collect.append(cmbtxt)\n",
    "\n",
    "    print \"Combined text from %d rows\" % len(collect)\n",
    "    return collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pct_area = np.mean(climb['is_area'])\n",
    "pct_route = np.mean(climb['is_route'])\n",
    "if pct_area + pct_route < (1 - sys.float_info.epsilon):\n",
    "    # TODO identify records with (route nor area) logical\n",
    "    print \"One or more records WAS NEITHER ROUTE NOR AREA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined text from 11851 rows\n"
     ]
    }
   ],
   "source": [
    "descriptive = get_total_climb_description(climb)\n",
    "# print \"The len of descriptive is %d\" % len(descriptive['cmb_txt'])\n",
    "# descriptive['cmb_txt'][-3:] # look at a few"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "CV12 = CountVectorizer(decode_error='ignore', stop_words='english', ngram_range=(1, 2))\n",
    "# also consider max_df=0.5, min_df=1\n",
    "word_count = CV12.fit_transform(descriptive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11851, 277963)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 95242)\t1\n",
      "  (0, 35199)\t1\n",
      "  (0, 119845)\t2\n",
      "  (0, 219758)\t1\n",
      "  (0, 139155)\t1\n",
      "  (0, 257007)\t3\n",
      "  (0, 36418)\t1\n",
      "  (0, 275640)\t1\n",
      "  (0, 56378)\t1\n",
      "  (0, 75957)\t1\n",
      "  (0, 237481)\t1\n",
      "  (0, 231857)\t1\n",
      "  (0, 25970)\t1\n",
      "  (0, 176240)\t1\n",
      "  (0, 99306)\t1\n",
      "  (0, 114584)\t1\n",
      "  (0, 193882)\t1\n",
      "  (0, 236353)\t2\n",
      "  (0, 269573)\t2\n",
      "  (0, 82905)\t2\n",
      "  (0, 264241)\t1\n",
      "  (0, 267834)\t3\n",
      "  (0, 259689)\t1\n",
      "  (0, 61656)\t4\n",
      "  (0, 222298)\t1\n",
      "  :\t:\n",
      "  (0, 149802)\t1\n",
      "  (0, 264468)\t1\n",
      "  (0, 120106)\t1\n",
      "  (0, 204408)\t1\n",
      "  (0, 264283)\t1\n",
      "  (0, 97218)\t1\n",
      "  (0, 96201)\t1\n",
      "  (0, 190935)\t1\n",
      "  (0, 62382)\t1\n",
      "  (0, 236589)\t1\n",
      "  (0, 69663)\t1\n",
      "  (0, 257195)\t1\n",
      "  (0, 151222)\t1\n",
      "  (0, 116411)\t1\n",
      "  (0, 83161)\t1\n",
      "  (0, 142810)\t1\n",
      "  (0, 149806)\t1\n",
      "  (0, 271307)\t1\n",
      "  (0, 169467)\t1\n",
      "  (0, 257339)\t1\n",
      "  (0, 275048)\t1\n",
      "  (0, 47273)\t1\n",
      "  (0, 252349)\t1\n",
      "  (0, 151190)\t1\n",
      "  (0, 92570)\t1\n"
     ]
    }
   ],
   "source": [
    "print word_count[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
