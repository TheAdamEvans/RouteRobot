{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "climb = pd.read_pickle('../database/test_data/_climb')\n",
    "vocab = pd.read_csv('../database/vocab.txt', header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11378, 71)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_segments = climb['description'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lemmatize, tokenize, vectorize text\n",
    "tfidf = TfidfVectorizer(\n",
    "    vocabulary=vocab,\n",
    "    strip_accents = 'unicode', lowercase=True, ngram_range=(1,2),\n",
    "    norm='l2', sublinear_tf=False, smooth_idf=True, use_idf=True\n",
    "    )\n",
    "X = tfidf.fit_transform(text_segments)\n",
    "# project sparse vocab space into lower rank dense represenation\n",
    "svd = TruncatedSVD(\n",
    "    n_components=256, random_state=42\n",
    "    )\n",
    "low_rank_X = svd.fit_transform(X)\n",
    "climb['dense_tfidf'] = [low_rank_X[i] for i in range(len(low_rank_X))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# climb['dense_tfidf'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parent_datum(climb, col, depth=2):\n",
    "    \"\"\" Lookup information from areas with specified depth\n",
    "    Parents have depth -2 because self.href is last\n",
    "    \"\"\"\n",
    "    collect = []\n",
    "    for cmb in climb['href']:\n",
    "        parent_href = climb.loc[cmb]['hierarchy']\n",
    "        if len(parent_href) < depth:\n",
    "            pdatum = float('NaN')\n",
    "        else:\n",
    "            pdatum = climb.loc[parent_href][col][-depth]\n",
    "        collect.append(pdatum)\n",
    "    return pd.Series(collect, index=climb.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "climb['parent_dense_tfidf'] = get_parent_datum(climb, 'dense_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_dense_matrix(climb, route_description_weight = 1.618):\n",
    "    \"\"\" Add dense representations of route and area descriptions together \"\"\"\n",
    "    collect = []\n",
    "    for _, cmb in climb.iterrows():\n",
    "        if isinstance(cmb['parent_dense_tfidf'],float):\n",
    "            if isinstance(cmb['dense_tfidf'],float):\n",
    "                collect.append(float('NaN'))\n",
    "            else:\n",
    "                collect.append(cmb['dense_tfidf'])\n",
    "        else:\n",
    "            area = cmb['parent_dense_tfidf']\n",
    "            route = cmb['dense_tfidf'] * route_description_weight\n",
    "            added = area + route * route_description_weight\n",
    "            # L2 normalize again\n",
    "            text_vector = added / norm(added, 2)\n",
    "            collect.append(text_vector)\n",
    "    return collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "climb['combined_dense_tfidf'] = combine_dense_matrix(climb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "low_rank_X = svd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11378, 256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_rank_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51413706598069409"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(svd.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51413706598069409"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(svd.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(low_rank_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirty_query = 'dean a big one juggy crimpy sunny'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sanitize(dirty_query, vocab):\n",
    "    \"\"\" Preprocess query string \"\"\"\n",
    "    query = dirty_query.strip().lower()\n",
    "    unigrams = query.split(' ')\n",
    "    bigrams = [ b[0]+' '+b[1] for l in [query] for b in zip(l.split(' ')[:-1], l.split(' ')[1:]) ]\n",
    "    tokens = [ t for t in (unigrams + bigrams) if t in vocab ]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = sanitize(dirty_query, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import norm\n",
    "from collections import Counter\n",
    "\n",
    "counts = dict(Counter(tokens))\n",
    "    \n",
    "text_vector = np.zeros((1, len(vocab)))\n",
    "for word, Tf in counts.items():\n",
    "    # multiply term frequency by inverse document frequency\n",
    "    tfidf_score = float(Tf) * 1 #idf_lookup[word]\n",
    "    # add score to this word's position in the array\n",
    "    text_vector[0,vocab.index(word)] = tfidf_score\n",
    "# L2 normalize\n",
    "text_vector = text_vector / norm(text_vector, 2)\n",
    "# cast as sparse\n",
    "# sparse_query = csr_matrix(text_vector)\n",
    "# return sparse_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2746)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5,  0.5,  0.5,  0.5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vector[text_vector > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comp = svd.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projected = np.dot(text_vector, comp.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = np.dot(projected, low_rank_X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11378)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 2746)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
